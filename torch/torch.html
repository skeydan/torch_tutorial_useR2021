<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />



<meta name="progressive" content="false" />
<meta name="allow-skip" content="false" />

<title>Getting started with torch</title>


<!-- highlightjs -->
<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>

<!-- taken from https://github.com/rstudio/rmarkdown/blob/67b7f5fc779e4cfdfd0f021d3d7745b6b6e17149/inst/rmd/h/default.html#L296-L362 -->
<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<script>
$(document).ready(function () {
  window.buildTabsets("section-TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>
<!-- end tabsets -->



</head>

<body>



<div class="pageContent band">
<div class="bandContent page">

<div class="topics">

<div id="section-welcome-to-torch-and-luz" class="section level2">
<h2>Welcome to <code>torch</code>! (And <code>luz</code>!)</h2>
<div id="section-torch" class="section level3">
<h3><code>torch</code></h3>
<p><a href="http:/torch.mlverse.org"><code>torch</code></a> is an <em>R-native</em> framework for fast array computation with automatic differentiation and rich neural-network functionality.</p>
<p><img src="images/torch_arch.png" /></p>
</div>
<div id="section-luz" class="section level3">
<h3><code>luz</code></h3>
<p>What <code>keras</code> is to <code>tensorflow</code> – a high-level API streamlining and instrumenting the training process – <code>luz</code> is to <code>torch</code>. While everything can be accomplished with <code>torch</code> alone, <code>luz</code></p>
<ul>
<li><p>provides a <em>keras</em>-like, declarative interface to the training process</p></li>
<li><p>removes boilerplate code</p></li>
<li><p>keeps track of <em>metrics</em> commonly used in data science, and allows you to define your own</p></li>
<li><p>provides a set of ready-to-use <em>callbacks</em> to control training, save model state, and more</p></li>
<li><p>offers a convenient interface for defining your own callbacks</p></li>
</ul>
</div>
<div id="section-ecosystem" class="section level3">
<h3>Ecosystem</h3>
<ul>
<li><p><a href="https:/github.com/mlverse/torch">torch</a></p></li>
<li><p><a href="https:/github.com/mlverse/luz">luz</a></p></li>
<li><p><a href="https:/github.com/mlverse/torchvision">torchvision</a></p></li>
<li><p><a href="https:/github.com/mlverse/torchdatasets">torchdatasets</a></p></li>
<li><p><a href="https:/github.com/mlverse/tabnet">tabnet</a></p></li>
<li><p>… and more!</p></li>
</ul>
</div>
<div id="section-our-goals-for-today" class="section level3">
<h3>Our goals for today</h3>
<ol style="list-style-type: decimal">
<li><p>Understand and use <code>torch</code> tensors and neural network modules; understand and apply automatic differentiation.</p></li>
<li><p>Use <code>luz</code> to train neural networks in a declarative way.</p></li>
<li><p>Get started with time-series forecasting in <code>torch</code>.</p></li>
</ol>
</div>
<div id="section-prerequisites" class="section level3">
<h3>Prerequisites</h3>
<p>To follow this tutorial, you will need to install the following packages:</p>
</div>
</div>
<div id="section-torch-tensors-modules-and-autograd" class="section level2">
<h2><code>torch</code> tensors, modules, and autograd</h2>
<div id="section-tensors" class="section level3">
<h3>Tensors</h3>
<div id="section-creating-tensors" class="section level4">
<h4>Creating tensors</h4>
<div id="section-way-1-from-r-values" class="section level5">
<h5>Way 1: From R values</h5>
<p>Tensors can be created directly from R values using <code>torch_tensor()</code>. Optionally, we can define tensor <em>attributes</em>, including the data type, the device it lives on, and more.</p>
<p>Here we are creating one-dimensional tensors (vectors):</p>
<pre class="r"><code>torch_tensor(1)
torch_tensor(1, dtype = torch_int())
torch_tensor(1, device = &quot;cuda&quot;)

torch_tensor(c(1, 2, 3)) # float tensor</code></pre>
<p>Two-dimensional tensors can be created from R matrices.</p>
<pre class="r"><code>torch_tensor(matrix(1:9, ncol = 3)) # integer tensor
torch_tensor(matrix(1:9, ncol = 3))$to(dtype = torch_float()) # cast to float

torch_tensor(matrix(1:9, ncol = 3, byrow = TRUE))</code></pre>
<p>Higher-dimensional tensors can be created from R arrays, but normally it is easier to use bulk creation functions.</p>
</div>
<div id="section-way-2-bulk-creation-functions." class="section level5">
<h5>Way 2: Bulk creation functions.</h5>
<p>Multi-dimensional tensors following some defineable pattern are created passing in the desired dimensionality. A few examples (more exist):</p>
<pre class="r"><code>torch_zeros(c(3, 3))
torch_rand(c(3, 3))</code></pre>
<p>Another often-used type of function is used specifying the desired range:</p>
<pre class="r"><code>torch_arange(1, 9)
torch_logspace(start = 0.1, end = 1.0, steps = 5)</code></pre>
</div>
</div>
<div id="section-converting-back-to-r" class="section level4">
<h4>Converting back to R</h4>
<p>Tensors are converted back to R using <code>as.numeric()</code>, <code>as.matrix()</code>, or <code>as.array()</code>:</p>
<pre class="r"><code>torch_tensor(2) %&gt;% as.numeric()

torch_ones(c(2, 2)) %&gt;% as.matrix() 

torch_ones(c(2, 2, 2)) %&gt;% as.array() </code></pre>
</div>
<div id="section-operations-on-tensors" class="section level4">
<h4>Operations on tensors</h4>
<p>A great number of operations can be performed on tensors. In general, there is a pair of <em>function</em> (not associated to any object) and corresponding <em>method</em> (“belonging” to a tensor instance) that do the same thing:</p>
<pre class="r"><code>t1 &lt;- torch_tensor(c(1, 2, 3))
t2 &lt;- torch_tensor(c(1, 2, 3))

torch_add(t1, t2)
t1$add(t2)</code></pre>
<p>In both cases, the original tensors are not modified; a new object is created. Normally, you would just assign this to a new variable:</p>
<pre class="r"><code>t3 &lt;- t1$add(t2)

t1
t3</code></pre>
<p>In the few cases where you need to modify the original tensor, you can make use of the corresponding underscore variants:</p>
<pre class="r"><code>t1$add_(t2)
t1</code></pre>
<p>Here are a few of the many matrix operations available. <code>$mul()</code> multiplies element-wise; <code>$matmul()</code> performs matrix multiplication; <code>$dot()</code> computes the dot product:</p>
<pre class="r"><code>t1$mul(t2)

# both work (torch has no concept of row vs. column vector)
t1$matmul(t2)
t1$t()$matmul(t2)

t1$dot(t2)</code></pre>
<p>You can see that <code>torch</code> makes no distinction between row and column vectors. Above, <code>$t()</code> transposes the vector <code>t1</code>, but the matrix multiplication will work without.</p>
</div>
<div id="section-reshaping-tensors" class="section level4">
<h4>Reshaping tensors</h4>
<p>Often, you will need to reshape a tensor. Among the most common operations are <code>$squeeze()</code> and <code>$unsqueeze()</code>. The former adds removes a singleton dimension at the specified position (where singleton means the dimension is of length <code>1</code>):</p>
<pre class="r"><code>t1 &lt;- torch_randn(c(1, 2, 3, 4))
t1

t1$squeeze(1)</code></pre>
<p>The latter, in contrast, adds a singleton dimension:</p>
<pre class="r"><code>t1$unsqueeze(4)</code></pre>
<p>This only works for singleton dimensions. <code>$view()</code> works for arbitrary reshaping, provided the number of elements allows for it. <code>t1</code> , above, has 24 values, which could as well be arranged as 6x4 or 1x24:</p>
<pre class="r"><code>t1$view(c(6, 4))

t1$view(24)</code></pre>
<p><code>$view()</code> does not actually create a separate, re-shaped instance of its input tensor; instead, it has the new variable refer to the same location in memory, and just stores some metadata that tell <code>torch</code> how the respective bytes should be read. There are cases when <code>$view()</code> cannot be used; in this case, you can always use <code>$reshape()</code> instead. In contrast to <code>$view()</code>, <code>$reshape()</code> will make a physical copy if necessary.</p>
</div>
<div id="section-indexing-and-slicing" class="section level4">
<h4>Indexing and slicing</h4>
<p>Indexing in <code>torch</code> is 1-based, just like in R overall. And just like in R, singleton dimensions will be dropped – unless you specify <code>drop = FALSE</code>:</p>
<pre class="r"><code>t1

t1[ , 1, , ]
t1[ , 1, , , drop = FALSE]</code></pre>
<p>Ranges of values (“slices”) can be accessed using the semicolon:</p>
<pre class="r"><code>t1[1, 1, 1:2, ]
t1[1, 1, 1:2, , drop = FALSE]</code></pre>
<p>A shortcut that does not exist in R (where the same syntax has different semantics), index <code>-1</code> is used to refer to the last element in a dimension:</p>
<pre class="r"><code>t2 &lt;- torch_tensor(1:17)
t2[-1] </code></pre>
</div>
<div id="section-broadcasting" class="section level4">
<h4>Broadcasting</h4>
<p>In <code>torch</code>, tensors may be <em>broadcasted</em>. The principle is the same as when, in R, we add a scalar to every element in a vector. But it goes farther than that. We don’t have the time to explain the rules in detail, but show a few examples as well as state the rules, for you to return at a later time.</p>
<p>Here, we “add” a matrix and a vector, resulting in the vector being added to every <em>row</em> of the matrix. This is possible only because <code>t2</code> has a singleton dimension in front.</p>
<pre class="r"><code>t1 &lt;- torch_randn(c(3,5))
t2 &lt;- torch_randn(c(1,5))

t1$add(t2)</code></pre>
<p>This example looks similar, but it involves an additional operation from <code>torch</code>’s side: <code>t2</code> is first virtually expanded to size 1x5 (a singleton dimension is added in front). Then, things go like above.</p>
<pre class="r"><code>t1 &lt;- torch_randn(c(3,5))
t2 &lt;- torch_randn(c(5))

t1$add(t2)</code></pre>
<p>As a final example, here we see both virtual addition of a singleton dimension (to <code>t1</code>) and the “reusability” of singleton dimensions shown in the first example. The latter idea is used twice, for <code>t1</code> as well as <code>t2</code>.</p>
</div>
<div id="section-appendix-broadcasting-rules" class="section level4">
<h4>Appendix: Broadcasting rules</h4>
<pre><code># 1 We align array shapes, starting from the right.
  
  # Example

  # t1, shape:     8  1  6  1
  # t2, shape:        7  1  5
  

# 2 Starting to look from the right, the sizes along aligned axes either have to match exactly,
#   or one of them has to be equal to 1.
#   In the latter case, the 1-dimensional tensor is broadcast to the larger one.

  # Example: this happens in the last (for t1) as well as the second-from-last dimension (for t2)

  # t1, shape:     8  1  6  5
  # t2, shape:        7  6  5


# 3 If on the left, one of the arrays has an additional axis (or more than one),
#   the other is virtually expanded to have a size of 1 in that place.
#   Then, broadcasting will happen as stated in (2).

  # Example: this happens in t1’s leftmost dimension. First, there is a virtual expansion

  # t1, shape:     8  1  6  1
  # t2, shape:     1  7  1  5

  # and then, broadcasting happens:
  
  # t1, shape:     8  1  6  1
  # t2, shape:     8  7  1  5</code></pre>
</div>
<div id="section-exercise-tensors" class="section level4">
<h4>Exercise: Tensors</h4>
<p>In the following exercises, try translating the R code into equivalent operations using <code>torch</code>.</p>
<ol style="list-style-type: decimal">
<li>Create two tensors representing a matrix and a vector, respectively:</li>
</ol>
<div class="tutorial-exercise" data-label="tensors1" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code># a matrix
m1 &lt;- matrix(1:32, ncol = 8, byrow = TRUE)

# really a vector
m2 &lt;- matrix(1:8, ncol = 1)

m1</code></pre>
<pre><code>     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8]
[1,]    1    2    3    4    5    6    7    8
[2,]    9   10   11   12   13   14   15   16
[3,]   17   18   19   20   21   22   23   24
[4,]   25   26   27   28   29   30   31   32</code></pre>
<pre class="text"><code>m2</code></pre>
<pre><code>     [,1]
[1,]    1
[2,]    2
[3,]    3
[4,]    4
[5,]    5
[6,]    6
[7,]    7
[8,]    8</code></pre>
<script type="application/json" data-opts-chunk="1">{"fig.width":6.5,"fig.height":4,"fig.retina":2,"fig.align":"default","fig.keep":"high","fig.show":"asis","out.width":624,"warning":true,"error":false,"message":true,"exercise.df_print":"paged","exercise.checker":"NULL"}</script>
</div>
<div class="tutorial-exercise-support" data-label="tensors1-hint" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>t1 &lt;- torch_tensor(matrix(1:32, ncol = 8, byrow = TRUE))
t2 &lt;- torch_tensor(1:8)

t1
t2</code></pre>
</div>
<ol start="2" style="list-style-type: decimal">
<li>Multiply the matrices, square all elements, sum them, and take the square root:</li>
</ol>
<div class="tutorial-exercise" data-label="tensors2" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>(m1 %*% m2)^2 %&gt;% sum() %&gt;% sqrt()</code></pre>
<pre><code>[1] 1425.729</code></pre>
<script type="application/json" data-opts-chunk="1">{"fig.width":6.5,"fig.height":4,"fig.retina":2,"fig.align":"default","fig.keep":"high","fig.show":"asis","out.width":624,"warning":true,"error":false,"message":true,"exercise.df_print":"paged","exercise.checker":"NULL"}</script>
</div>
<div class="tutorial-exercise-support" data-label="tensors2-hint" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>t1$matmul(t2)$square()$sum()$to(dtype = torch_float())$sqrt()</code></pre>
</div>
<p>[Note how we need to cast to <code>float</code> in order to be able to call <code>torch_sqrt()</code>.]</p>
<ol start="3" style="list-style-type: decimal">
<li>Multiply each row in <code>m1</code> by the vector <code>m2</code> (element-wise):</li>
</ol>
<div class="tutorial-exercise" data-label="tensors3" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>m1 * rbind(t(m2), t(m2), t(m2), t(m2))</code></pre>
<pre><code>     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8]
[1,]    1    4    9   16   25   36   49   64
[2,]    9   20   33   48   65   84  105  128
[3,]   17   36   57   80  105  132  161  192
[4,]   25   52   81  112  145  180  217  256</code></pre>
<script type="application/json" data-opts-chunk="1">{"fig.width":6.5,"fig.height":4,"fig.retina":2,"fig.align":"default","fig.keep":"high","fig.show":"asis","out.width":624,"warning":true,"error":false,"message":true,"exercise.df_print":"paged","exercise.checker":"NULL"}</script>
</div>
<div class="tutorial-exercise-support" data-label="tensors3-hint" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>t1 * t2</code></pre>
</div>
<p>[Note how broadcasting takes care of the duplication for us. Also, note how no transposition is needed, as <code>torch</code> has no concept of row vectors vs. column vectors.]</p>
<ol start="4" style="list-style-type: decimal">
<li>Transpose the matrix <code>m1</code>, and compute column sums. (This should yield 4 values.)</li>
</ol>
<div class="tutorial-exercise" data-label="tensors4" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>t(m1) %&gt;% apply(2, sum)</code></pre>
<pre><code>[1]  36 100 164 228</code></pre>
<script type="application/json" data-opts-chunk="1">{"fig.width":6.5,"fig.height":4,"fig.retina":2,"fig.align":"default","fig.keep":"high","fig.show":"asis","out.width":624,"warning":true,"error":false,"message":true,"exercise.df_print":"paged","exercise.checker":"NULL"}</script>
</div>
<div class="tutorial-exercise-support" data-label="tensors4-hint" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>t1$t()$sum(dim = 1)</code></pre>
</div>
<p>[Note how applying the sum over dimension 1 (not 2) collapses the rows. Try to view it like this: Given an index into the dimensions, in R, we think “group by”. In torch, we think “collapse”.]</p>
<ol start="5" style="list-style-type: decimal">
<li>Standardize <code>m1</code> , subtracting the mean and dividing by the standard deviation.</li>
</ol>
<div class="tutorial-exercise" data-label="tensors5" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>(m1 - mean(m1)) / sd(m1)</code></pre>
<pre><code>            [,1]       [,2]       [,3]       [,4]       [,5]       [,6]
[1,] -1.65230555 -1.5457052 -1.4391048 -1.3325045 -1.2259041 -1.1193038
[2,] -0.79950269 -0.6929023 -0.5863020 -0.4797016 -0.3731013 -0.2665009
[3,]  0.05330018  0.1599005  0.2665009  0.3731013  0.4797016  0.5863020
[4,]  0.90610304  1.0127034  1.1193038  1.2259041  1.3325045  1.4391048
           [,7]        [,8]
[1,] -1.0127034 -0.90610304
[2,] -0.1599005 -0.05330018
[3,]  0.6929023  0.79950269
[4,]  1.5457052  1.65230555</code></pre>
<script type="application/json" data-opts-chunk="1">{"fig.width":6.5,"fig.height":4,"fig.retina":2,"fig.align":"default","fig.keep":"high","fig.show":"asis","out.width":624,"warning":true,"error":false,"message":true,"exercise.df_print":"paged","exercise.checker":"NULL"}</script>
</div>
<div class="tutorial-exercise-support" data-label="tensors5-hint" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>t1 &lt;- t1$to(dtype = torch_float())
(t1 - t1$mean()) / t1$std()</code></pre>
</div>
<p>Just like <code>torch_sum()</code>, <code>torch_mean()</code> and <code>torch_std()</code> need their input to be of type <code>float</code>.</p>
</div>
</div>
<div id="section-automatic-differentiation-with-autograd" class="section level3">
<h3>Automatic differentiation with <em>autograd</em></h3>
<div id="section-how-it-works" class="section level4">
<h4>How it works</h4>
<p><code>torch</code> autograd provides automatic differentiation for operations executed on tensors. For this to happen, the “source” (or “leaf”, as <code>torch</code> calls it) tensor – the one <em>with respect to which</em> we’d like derivatives computed – needs to be created with <code>requires_grad = TRUE</code>. Let’s call it <code>a</code>:</p>
<pre class="r"><code>a &lt;- torch_tensor(matrix(1:4, ncol = 2, byrow = TRUE), dtype = torch_float(), requires_grad = TRUE)</code></pre>
<p>In this example, <code>c</code>, the output, depends on <code>a</code> via <code>b</code>:</p>
<pre class="r"><code>b &lt;- a$mul(2)
c &lt;- b$sum()</code></pre>
<p>So far, no derivatives have been computed yet. But <code>torch</code> knows what to do should we ask it to. More precisely, it knows the concrete operations it’ll have to compute the derivatives for:</p>
<pre class="r"><code>c$grad_fn
b$grad_fn</code></pre>
<p>To actually have them computed, call <code>$backward()</code> on the output tensor:</p>
<pre class="r"><code>c$backward()</code></pre>
<p>Now the gradient of <code>c</code> with respect to <code>a</code> can be found in <code>a</code>’s <code>$grad</code> field.</p>
<pre class="r"><code>a$grad</code></pre>
<p>When we’re updating a “leaf” tensor, for example in optimization, we don’t want <code>torch</code> to record that operation for later computation of derivatives. In these cases, we need to tell it to exempt the operation in question from the process:</p>
<pre class="r"><code>with_no_grad( {
  a$sub_(0.1 * a$grad)
})

a</code></pre>
</div>
<div id="section-minimizing-a-function-with-autograd" class="section level4">
<h4>Minimizing a function with <em>autograd</em></h4>
<p>We can use <em>autograd</em> to minimize a function. We define a parameter to hold <span class="math inline">\(\mathbf{x}\)</span>. Then, in a loop, we evaluate the function at the current <span class="math inline">\(\mathbf{x}\)</span>, compute the gradient, and subtract a fraction of the gradient from <span class="math inline">\(\mathbf{x}\)</span>.</p>
<pre class="r"><code># function to minimize
f &lt;- function(x) x^2 - 7

# we start from x = 11
param &lt;- torch_tensor(11, requires_grad = TRUE)

# learning rate: fraction of gradient to subtract
lr &lt;- 0.1

for (i in 1:num_iterations) {
  
  # call function on current parameter value

  # compute gradient of value w.r.t. parameter

  # update parameter

}</code></pre>
<p>In the exercise, you’re asked to fill in the missing pieces.</p>
</div>
<div id="section-exercise-function-minimization" class="section level4">
<h4>Exercise: Function minimization</h4>
<p>Fill in the lines marked “TBD”. When you have the code running, experiment with the learning rate and compare the results. What is a good learning rate for this problem?</p>
<div class="tutorial-exercise" data-label="autograd" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code># function to minimize
f &lt;- function(x) x^2 - 7

# we start from x = 11
param &lt;- torch_tensor(11, requires_grad = TRUE)

# learning rate: fraction of gradient to subtract
lr &lt;- 0.1

for (i in 1:10) {
  
  cat(&quot;Iteration: &quot;, i, &quot;\n&quot;)
  
  # call function with current parameter
  value &lt;- 777 # TBD
  cat(&quot;Value is: &quot;, as.numeric(value), &quot;\n&quot;)
  
  # compute gradient of value w.r.t. parameter
  # TBD
  # uncomment the following line when ready
  # cat(&quot;Gradient is: &quot;, as.matrix(param$grad), &quot;\n&quot;)
  
  # update parameter
  # wrap in with_no_grad
  with_no_grad({
    # subtract a fraction of gradient from param
    # TBD
    
    # zero out on every iteration (would accumulate otherwise)
    # TBD
  })
  
  cat(&quot;After update: Param is: &quot;, as.matrix(param), &quot;\n\n&quot;)
  
  if (abs(-7 - as.numeric(value)) &lt; 0.00005) break
}</code></pre>
<pre><code>Iteration:  1 
Value is:  777 
After update: Param is:  11 

Iteration:  2 
Value is:  777 
After update: Param is:  11 

Iteration:  3 
Value is:  777 
After update: Param is:  11 

Iteration:  4 
Value is:  777 
After update: Param is:  11 

Iteration:  5 
Value is:  777 
After update: Param is:  11 

Iteration:  6 
Value is:  777 
After update: Param is:  11 

Iteration:  7 
Value is:  777 
After update: Param is:  11 

Iteration:  8 
Value is:  777 
After update: Param is:  11 

Iteration:  9 
Value is:  777 
After update: Param is:  11 

Iteration:  10 
Value is:  777 
After update: Param is:  11 </code></pre>
<script type="application/json" data-opts-chunk="1">{"fig.width":6.5,"fig.height":4,"fig.retina":2,"fig.align":"default","fig.keep":"high","fig.show":"asis","out.width":624,"warning":true,"error":false,"message":true,"exercise.df_print":"paged","exercise.checker":"NULL"}</script>
</div>
<div class="tutorial-exercise-support" data-label="autograd-hint" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code># function to minimize
f &lt;- function(x) x^2 - 7

# we start from x = 11
param &lt;- torch_tensor(11, requires_grad = TRUE)

# learning rate: fraction of gradient to subtract
lr &lt;- 0.5

for (i in 1:10) {
  
  cat(&quot;Iteration: &quot;, i, &quot;\n&quot;)
  
  value &lt;- f(param)
  cat(&quot;Value is: &quot;, as.numeric(value), &quot;\n&quot;)
  
  # compute gradient of value w.r.t. parameter
  value$backward()
  cat(&quot;Gradient is: &quot;, as.matrix(param$grad), &quot;\n&quot;)
  
  # update
  with_no_grad({
    param$sub_(lr * param$grad)
    # zero out on every iteration (would accumulate otherwise)
    param$grad$zero_()
  })
  
  cat(&quot;After update: Param is: &quot;, as.matrix(param), &quot;\n\n&quot;)
  
  if (abs(-7 - as.numeric(value)) &lt; 0.00005) break
}</code></pre>
</div>
</div>
</div>
<div id="section-modules-and-optimizers" class="section level3">
<h3>Modules and optimizers</h3>
<p>While everything can be done with tensors and <em>autograd</em> alone, coding a large neural network that way would be a pretty cumbersome task. Luckily, doing so is not necessary. For one, <code>torch</code> provides a rich set of neural network <em>modules</em> that hide away layer logic; and secondly, its <em>optimizers</em> encapsulate established optimization algorithms known for their efficiency in neural-network settings.</p>
<div id="section-neural-network-modules" class="section level4">
<h4>Neural network modules</h4>
<p><code>torch</code> uses the term module for individual <em>layers</em> (e.g., linear layer, convolutional layer …) as well as <em>models</em>, a.k.a. neural networks. The logic here is that modules are composable; a model/module is nothing but a composition of smaller modules, which again may contain yet smaller modules, etc.</p>
<div id="section-linear-module" class="section level5">
<h5>Linear module</h5>
<p>Here is an affine transformation, coded manually:</p>
<pre class="r"><code># input data
x &lt;- torch_randn(c(7,2))

# weights
w &lt;- torch_tensor(c(0.1, 0.1), requires_grad = TRUE)
# bias
b &lt;- torch_tensor(0.5, requires_grad = TRUE)
  
x$matmul(w) + b  </code></pre>
<p>We can achieve the same using a linear module:</p>
<pre class="r"><code>l &lt;- nn_linear(in_features = 2, out_features = 1)
l(x)</code></pre>
<p>The result is different from above, because there we defined the weight ourselves. By default, <code>torch</code> will initialize the weights uniformly, with values ranging between <code>[-sqrt(num_features), sqrt(num_features)]</code>.</p>
<pre class="r"><code>l$weight </code></pre>
<p>Just to prove the point, we can manually initialize the module’s weights:</p>
<pre class="r"><code>nn_init_constant_(l$weight, 0.1)
nn_init_constant_(l$bias, 0.5)

l(x)</code></pre>
<p>With modules, we get automatic differentiation for free.</p>
<p>Assume we want to minimize the sum of the outputs.</p>
<pre class="r"><code>loss &lt;- l(x)$sum() 
loss$grad_fn</code></pre>
<p>We will still have to call <code>$backward()</code> to see actual derivatives being computed. Here they are still undefined:</p>
<pre class="r"><code>l$weight$grad
l$bias$grad</code></pre>
<p>Calling <code>$backward()</code> …</p>
<pre class="r"><code>loss$backward()

l$weight$grad
l$bias$grad</code></pre>
</div>
<div id="section-examples-of-other-modules" class="section level5">
<h5>Examples of other modules</h5>
<p>Many more modules exist. Here is a tensor mimicking a 32x32 RGB image:</p>
<pre class="r"><code>img &lt;- torch_rand(c(1, 3, 32, 32))</code></pre>
<p>Now <code>nn_conv2d()</code> is used to create a convolutional layer, and its 3x3 filter is applied to the image:</p>
<pre class="r"><code>conv &lt;- nn_conv2d(in_channels = 3, out_channels = 1, kernel_size = 3, padding = 1)

conv(img)</code></pre>
<p>Another module commonly used in image processing is <code>nn_max_pool2d()</code> for spatial downsizing:</p>
<pre class="r"><code>pool &lt;- nn_max_pool2d(kernel_size = 2)
conv(img) %&gt;% pool()</code></pre>
<p>In the third section of this tutorial, we will encounter modules common in time series processing.</p>
</div>
<div id="section-composing-modules" class="section level5">
<h5>Composing modules</h5>
<p>To build a “model” from “layers” such as the ones we showed above, we can use <code>nn_sequential()</code>. Here is a model that has two linear layers, with between them a ReLU module (<code>nn_relu()</code>). ReLU stands for “Rectified Linear Unit”; its purpose is to introduce some nonlinearity to this otherwise linear model. (It does this by setting all negative values to zero.)</p>
<pre class="r"><code>model &lt;- nn_sequential(
  nn_linear(2, 16),
  nn_relu(),
  nn_linear(16, 1)
)

model$parameters

model(x)</code></pre>
<p>You can also define your own modules. We’ll see examples of this in the second part.</p>
</div>
</div>
<div id="section-optimizers" class="section level4">
<h4>Optimizers</h4>
<p>Among the most commonly-used optimizers in deep learning are Adam (<code>optim_adam()</code>), RMSProp (<code>optim_rmsprop()</code>), and Stochastic Gradient Descent (SGD; <code>optim_sgd()</code>).</p>
<p>Here, we use <code>optim_adam()</code> to demonstrate their use.</p>
<pre class="r"><code># some toy data
x &lt;- torch_tensor(c(1.2, 0.8, 0.7))
y &lt;- torch_tensor(1)</code></pre>
<p>When an optimizer object is created, it needs to be told what to optimize – namely, the model’s parameters. Most optimizers also need to be passed the learning rate.</p>
<pre class="r"><code>model &lt;- nn_sequential(
  nn_linear(3, 8),
  nn_relu(),
  nn_linear(8, 1)
)

optimizer &lt;- optim_adam(model$parameters, lr = 0.01)</code></pre>
<p>We obtain a prediction:</p>
<pre class="r"><code>prediction &lt;- model(x)
prediction</code></pre>
<p>We then use one of <code>torch</code>’s built-in loss functions to compute the loss (here, mean squared error):</p>
<pre class="r"><code>loss &lt;- nnf_mse_loss(prediction, y)
loss</code></pre>
<p>We call <code>$backward()</code> on the loss to have gradients computed:</p>
<pre class="r"><code>loss$backward()</code></pre>
<p>Now the gradients are known, but no changes have been made to the model’s parameters yet.</p>
<pre class="r"><code>model$parameters</code></pre>
<p>Calling <code>$step()</code> on the optimizer will make those changes:</p>
<pre class="r"><code>optimizer$step()</code></pre>
<pre class="r"><code>model$parameters</code></pre>
<p>When actually training a network, we call the optimizer in a loop. We show an example of this next.</p>
<div id="section-a-neural-network" class="section level5">
<h5>A neural network</h5>
<p>First, we create the training data.</p>
<pre class="r"><code># input dimensionality (number of input features)
d_in &lt;- 3
# output dimensionality (number of predicted features)
d_out &lt;- 1
# number of observations in training set
n &lt;- 100

# create random data
x &lt;- torch_randn(n, d_in)
y &lt;- x[, 1, NULL] * 0.2 - x[, 2, NULL] * 1.3 - x[, 3, NULL] * 0.5 + torch_randn(n, 1)</code></pre>
<p>Then, we define the network.</p>
<pre class="r"><code># dimensionality of hidden layer
d_hidden &lt;- 32

model &lt;- nn_sequential(
  nn_linear(d_in, d_hidden),
  nn_relu(),
  nn_linear(d_hidden, d_out)
)</code></pre>
<p>We create the optimizer:</p>
<pre class="r"><code>learning_rate &lt;- 0.08

# optimizer applies gradient updates for us
optimizer &lt;- optim_adam(model$parameters, lr = learning_rate)</code></pre>
<p>And we ’re ready for the training loop. In a loop, we</p>
<ul>
<li><p>obtain model predictions;</p></li>
<li><p>compute the loss;</p></li>
<li><p>propagate back the loss through the network and update the parameters.</p></li>
</ul>
<p>Note how when optimizing in a loop, we need to zero out gradients on every iteration.</p>
<pre class="r"><code>for (t in 1:200) {
  
  ### -------- Forward pass -------- 
  y_pred &lt;- model(x)
  
  ### -------- compute loss -------- 
  # mean squared error loss
  loss &lt;- nnf_mse_loss(y_pred, y, reduction = &quot;sum&quot;)
  if (t %% 10 == 0)
    cat(&quot;Epoch: &quot;, t, &quot;   Loss: &quot;, loss$item(), &quot;\n&quot;)
  
  ### -------- Backpropagation -------- 
  
  # Need to zero out the gradients before the backward pass, as they&#39;d accumulate otherwise
  optimizer$zero_grad()
  
  # compute gradients 
  loss$backward()
  
  # update weights 
  optimizer$step()
}</code></pre>
<p>While a lot more convenient than working with tensors only, this is still a pretty low-level way of training a neural network, and needs special attention to be devoted to particularities (like zeroing out the gradients). In part two, we’ll see how to train neural networks much more comfortably with <code>luz</code>.</p>
</div>
</div>
<div id="section-exercise-training-a-neural-network" class="section level4">
<h4>Exercise: Training a neural network</h4>
<p>Below, you find the above end-to-end code to train a neural network. Try experimenting with it a bit:</p>
<ul>
<li><p>If you change the learning rate, what happens?</p></li>
<li><p>Try other optimizers, such as <code>optim_sgd()</code>. How does that affect training?</p></li>
</ul>
<div class="tutorial-exercise" data-label="modules" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code># input dimensionality (number of input features)
d_in &lt;- 3
# output dimensionality (number of predicted features)
d_out &lt;- 1
# number of observations in training set
n &lt;- 100

# create random data
x &lt;- torch_randn(n, d_in)
y &lt;- x[, 1, NULL] * 0.2 - x[, 2, NULL] * 1.3 - x[, 3, NULL] * 0.5 + torch_randn(n, 1)

# dimensionality of hidden layer
d_hidden &lt;- 32

model &lt;- nn_sequential(
  nn_linear(d_in, d_hidden),
  nn_relu(),
  nn_linear(d_hidden, d_out)
)

learning_rate &lt;- 0.08

# optimizer applies gradient updates for us
optimizer &lt;- optim_adam(model$parameters, lr = learning_rate)

for (t in 1:200) {
  
  ### -------- Forward pass -------- 
  y_pred &lt;- model(x)
  
  ### -------- compute loss -------- 
  # mean squared error loss
  loss &lt;- nnf_mse_loss(y_pred, y, reduction = &quot;sum&quot;)
  if (t %% 10 == 0)
    cat(&quot;Epoch: &quot;, t, &quot;   Loss: &quot;, loss$item(), &quot;\n&quot;)
  
  ### -------- Backpropagation -------- 
  
  # Need to zero out the gradients before the backward pass, as they&#39;d accumulate otherwise
  optimizer$zero_grad()
  
  # compute gradients 
  loss$backward()
  
  # update weights 
  optimizer$step()
}</code></pre>
<pre><code>Epoch:  10    Loss:  98.00224 
Epoch:  20    Loss:  83.34789 
Epoch:  30    Loss:  73.32167 
Epoch:  40    Loss:  63.78309 
Epoch:  50    Loss:  56.94036 
Epoch:  60    Loss:  57.7351 
Epoch:  70    Loss:  50.0152 
Epoch:  80    Loss:  44.02956 
Epoch:  90    Loss:  40.27573 
Epoch:  100    Loss:  38.44748 
Epoch:  110    Loss:  35.70034 
Epoch:  120    Loss:  35.81842 
Epoch:  130    Loss:  34.5412 
Epoch:  140    Loss:  31.31835 
Epoch:  150    Loss:  28.56025 
Epoch:  160    Loss:  27.58221 
Epoch:  170    Loss:  26.65957 
Epoch:  180    Loss:  26.27227 
Epoch:  190    Loss:  26.4375 
Epoch:  200    Loss:  26.03418 </code></pre>
<script type="application/json" data-opts-chunk="1">{"fig.width":6.5,"fig.height":4,"fig.retina":2,"fig.align":"default","fig.keep":"high","fig.show":"asis","out.width":624,"warning":true,"error":false,"message":true,"exercise.df_print":"paged","exercise.checker":"NULL"}</script>
</div>
</div>
</div>
</div>
<div id="section-training-neural-networks-with-luz" class="section level2">
<h2>Training neural networks with <code>luz</code></h2>
<p><code>luz</code> is a high-level API for <code>torch</code> that allows you to train neural networks in a declarative style.</p>
<p>With <code>luz</code>, the overall flow looks a lot like in <code>keras</code>:</p>
<ol style="list-style-type: decimal">
<li><p>You define a model.</p></li>
<li><p>You use <code>setup()</code> to configure it with a loss function, an optimizer, and a set of metrics.</p></li>
<li><p>You train it using <code>fit()</code>, passing in the training and (optionally) validation data, as well as the number of epochs to train for and a set of callbacks (both optional).</p></li>
</ol>
<div id="section-end-to-end-example-mnist" class="section level3">
<h3>End-to-end example: MNIST</h3>
<p>To introduce <code>luz</code>, we are going to do the “hello world” of deep learning: digit classification on the (in-)famous MNIST dataset. MNIST is available as part of the <code>torchvision</code> package.</p>
<div id="section-data" class="section level4">
<h4>Data</h4>
<p>In <code>torch</code> , data is fed to a network using <code>dataset</code>s and <code>dataloaders</code>. Their respective responsibilities are:</p>
<ul>
<li><p><code>dataset</code>: Return a single training (or validation, or test) item (in supervised learning, a list of input and target). Optionally, take care of any pre-processing required.</p></li>
<li><p><code>dataloader</code>: Feed the data to the model. Normally, this happens in <em>batches</em> of configurable size. Optionally, a <code>dataloader</code> may shuffle the data, and arrange for parallelization over a subset of available processors.</p></li>
</ul>
<p><code>torchvision</code> comes with a few image datasets, requestable via <code>xxx_dataset()</code>. They will be downloaded and prepared the first time they’re instantiated (unless the data exist already in the specified location).</p>
<p>Since we don’t really need the full MNIST dataset for this demonstration, we only prepare the test split (indicated by the line <code>train = FALSE</code> below). We’ll split it up manually into training and validation parts in a minute.</p>
<p>In the dataset constructor, the argument <code>transform =</code> serves to tell <code>torch</code> how the images should be pre-processed.</p>
<pre class="r"><code>dir &lt;- &quot;~/Downloads/mnist&quot; 

ds &lt;- mnist_dataset(
  dir,
  train = FALSE,
  transform = function(x) {
    x %&gt;% transform_to_tensor() 
  }
)</code></pre>
<p><code>ds</code> now has 10,000 image-label pairs:</p>
<pre class="r"><code>length(ds)</code></pre>
<p>We can use indexing to inspect them:</p>
<pre class="r"><code>ds[1]</code></pre>
<p>Using <code>dataset_subset()</code>, we divide those 10,000 pairs into training and validation sets:</p>
<pre class="r"><code>train_id &lt;- sample.int(length(ds), size = 0.7*length(ds))
train_ds &lt;- dataset_subset(ds, indices = train_id)
valid_ds &lt;- dataset_subset(ds, indices = which(!seq_along(ds) %in% train_id))</code></pre>
<p>Next, we create the respective <code>dataloader</code>s.</p>
<pre class="r"><code>train_dl &lt;- dataloader(train_ds, batch_size = 128, shuffle = TRUE)
valid_dl &lt;- dataloader(valid_ds, batch_size = 128, shuffle = FALSE)</code></pre>
<p>With <code>dataloader</code>s, <code>length()</code> indicates the number of <em>batches</em>:</p>
<pre class="r"><code>length(train_dl)
length(valid_dl)</code></pre>
</div>
<div id="section-model" class="section level4">
<h4>Model</h4>
<p>The model is a convolutional neural network that successively filters and downsizes its input, to finally arrive at a class prediction. There are ten types of digits (0-9), and for each digit, it will output a score for each of the ten possible labels.</p>
<p>In the definition of the model, note the parameter <code>num_classes</code>. In this example, there is no real need to parameterize the number of classes the model can work with; however, we’d like to show how with <code>luz</code>, you can keep the model definition flexible and pass in the desired configuration at training time.</p>
<pre class="r"><code>net &lt;- nn_module(
  &quot;Net&quot;,
  initialize = function(num_classes) {
    self$conv1 &lt;- nn_conv2d(1, 32, 3, 1)
    self$conv2 &lt;- nn_conv2d(32, 64, 3, 1)
    self$dropout1 &lt;- nn_dropout2d(0.25)
    self$dropout2 &lt;- nn_dropout2d(0.5)
    self$fc1 &lt;- nn_linear(9216, 128)
    self$fc2 &lt;- nn_linear(128, num_classes)
  },
  forward = function(x) {
    x %&gt;% 
      self$conv1() %&gt;% 
      nnf_relu() %&gt;% 
      self$conv2() %&gt;% 
      nnf_relu() %&gt;% 
      nnf_max_pool2d(2) %&gt;% 
      self$dropout1() %&gt;% 
      torch_flatten(start_dim = 2) %&gt;% 
      self$fc1() %&gt;% 
      nnf_relu() %&gt;% 
      self$dropout2() %&gt;% 
      self$fc2()
  }
)</code></pre>
</div>
<div id="section-training" class="section level4">
<h4>Training</h4>
<p>Now that we have the model definition, all that separates us from watching it being trained are two calls to <code>luz</code>: <code>setup()</code> and <code>fit()</code>.</p>
<ul>
<li><p>Using <code>setup()</code>, we configure the loss function and the optimizer to be used; additionally, we can ask for a set of metrics to be computed.</p></li>
<li><p>By calling <code>fit</code>, we start the training process. The first argument is always the <code>dataloader</code> containing the training data; the remaining arguments are optional and include the number of epochs to train for, and possibly another <code>dataloader</code> for validation.</p></li>
</ul>
<p>While <code>setup()</code> and <code>fit()</code> are “obligatory”, <code>set_hparams()</code>, located between the two, is not. This function can be used to set variables used in the model; here we’re passing in the desired value for <code>num_classes</code> referred to above.</p>
<pre class="r"><code>fitted &lt;- net %&gt;%
  setup(
    loss = nn_cross_entropy_loss(),
    optimizer = optim_adam,
    metrics = list(
      luz_metric_accuracy()
    )
  ) %&gt;%
  set_hparams(num_classes = 10) %&gt;%
  fit(train_dl, epochs = 3, valid_data = valid_dl, verbose = TRUE)</code></pre>
</div>
<div id="section-predictions" class="section level4">
<h4>Predictions</h4>
<p>Predictions may be obtained using <code>predict()</code>, passing in the fitted model and the <code>dataloader</code> for which we want predictions computed.</p>
<p>These predictions are nothing but the output from the model’s final layer:</p>
<pre class="r"><code>preds &lt;- predict(fitted, valid_dl)
preds[1:10, ]</code></pre>
<p>The best-matching class here is the one for which the tensor value (the <em>score</em>) is highest. If we want actual probabilities, we can run the raw scores through a <em>softmax</em>:</p>
<pre class="r"><code>(nnf_softmax(preds[1:10, ], dim = 2))$to(device = &quot;cpu&quot;) %&gt;% as.matrix() %&gt;% round(2)</code></pre>
</div>
<div id="section-saving-and-loading-models" class="section level4">
<h4>Saving and loading models</h4>
<p>Rounding up on <code>luz</code> essentials, here are its helper functions to save and load models:</p>
<pre class="r"><code>luz_save(fitted, &quot;mnist-cnn.pt&quot;)
copy &lt;- luz_load(&quot;mnist-cnn.pt&quot;)</code></pre>
</div>
</div>
<div id="section-exercise-callbacks" class="section level3">
<h3>Exercise: Callbacks</h3>
<p>Callbacks offer an extremely flexible way to customize the training routine. <code>luz</code> itself uses callbacks internally, too, to compute metrics, for example, or to display training progress.</p>
<p>Here is a simple callback that gets active at two specified categories of “time”:</p>
<ol style="list-style-type: decimal">
<li><p>Whenever training has finished on a single batch (<code>on_train_batch_end()</code>).</p></li>
<li><p>Whenever training has completed one full epoch (<code>on_epoch_end())</code>.</p></li>
</ol>
<pre class="r"><code>print_callback &lt;- luz_callback(
  
  name = &quot;print_callback&quot;,
  
  initialize = function(message) {
    self$message &lt;- message
  },
  
  on_train_batch_end = function() {
    cat(&quot;Iteration &quot;, ctx$iter, &quot;\n&quot;)
  },
  
  on_epoch_end = function() {
    cat(self$message, &quot;\n&quot;)
  }
)</code></pre>
<p>Callbacks are passed to <code>luz</code> in the <code>fit()</code> call:</p>
<pre class="r"><code>fitted &lt;- net %&gt;%
  setup(...) %&gt;%
  fit(..., callbacks = list(
    print_callback(message = &quot;Done!&quot;)
  ))</code></pre>
<p>Via a special-purpose context reference (<code>ctx</code>), callbacks have access to a large number of model-internal and process-dependent objects, such as the model itself, a list of optimizers used, the current epoch, and more.</p>
<p>For this exercise, implement a callback that at the end of every epoch, says “Done with epoch &lt;n&gt;”, and plug it into the training routine.</p>
<div class="tutorial-exercise" data-label="custom-callback" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>which_epoch_callback &lt;- luz_callback(
  
  name = &quot;which_epoch_callback&quot;,
  
  # TBD
  
  
)</code></pre>
<script type="application/json" data-opts-chunk="1">{"fig.width":6.5,"fig.height":4,"fig.retina":2,"fig.align":"default","fig.keep":"high","fig.show":"asis","out.width":624,"warning":true,"error":false,"message":true,"exercise.df_print":"paged","exercise.checker":"NULL"}</script>
</div>
<div class="tutorial-exercise-support" data-label="custom-callback-hint" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>which_epoch_callback &lt;- luz_callback(
  
  name = &quot;which_epoch_callback&quot;,
  
  on_epoch_end = function() {
    cat(&quot;Done with epoch&quot;, ctx$epoch, &quot;\n&quot;)
  }
)</code></pre>
</div>
</div>
<div id="section-exercise-creating-a-custom-metric" class="section level3">
<h3>Exercise: Creating a custom metric</h3>
<p>While <code>luz</code> provides a great number of metrics, you can easily implement your own if needed. <em>Metric</em> objects keep running aggregates of the indicator in question. At each epoch, aggregates are re-initialized to their starting values (zero, in most cases).</p>
<p>A <code>luz</code> metric is an R6 object with three methods:</p>
<ul>
<li><p><code>initialize()</code>, used to define the starting values for every variable to keep track of;</p></li>
<li><p><code>update()</code>, telling <code>luz</code> how to update these variables at every training (validation, resp.) step; and</p></li>
<li><p><code>compute()</code>, used to define the indicator to be returned to the user.</p></li>
</ul>
<p>Below, you’ll be tasked to implement accuracy yourself. Here is an outline of what’s to be done:</p>
<pre class="r"><code>my_accuracy &lt;- luz_metric(
  abbrev = &quot;my_acc&quot;, 
  
  initialize = function() {
    # initialize two fields:
    # one to hold the number of correct predictions
    # one to hold the running total of predictions
    # e.g.
    # self$correct &lt;-
    # self$total &lt;-
  },
 
  update = function(preds, target) {
    # 1: use pred (function argument no. 1) to compute the indices of the most likely class (for the complete batch)
    # pred &lt;- 
    
    # 2: update self$correct: add number of correct predictions
    # self$correct &lt;- 
    
    # 3: update the running total of predictions
    # self$total &lt;- 
  },
  
  compute = function() {
    # return proportion of correct predictions
  }
)</code></pre>
<p>You can substitute your own implementation of accuracy in the training process, replacing <code>luz_metric_accuracy()</code>. Before doing that, test your implementation standalone, comparing with the official implementation:</p>
<pre class="r"><code>preds_10 &lt;- preds[1:10, ]
target_10 &lt;- valid_ds[1:10]$y

metric &lt;- luz_metric_accuracy()
metric &lt;- metric$new()
metric$update(preds_10, target_10)
metric$compute()

metric2 &lt;- my_accuracy()
metric2 &lt;- metric2$new()
metric2$update(preds_10, target_10)
metric2$compute()</code></pre>
<div class="tutorial-exercise" data-label="custom-metric" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>my_accuracy &lt;- luz_metric(
  abbrev = &quot;my_acc&quot;, 
  
  initialize = function() {
    # initialize two fields:
    # one to hold the number of correct predictions
    # one to hold the running total of predictions
    # e.g.
    # self$correct &lt;-
    # self$total &lt;-
  },
 
  update = function(preds, target) {
    # 1: use preds (function input no. 1) to compute the indices of the classes with the highest scores
    # pred &lt;- 
    
    # 2: update self$correct: add number of correct predictions
    # self$correct &lt;- 
    
    # 3: update the running total of predictions
    # self$total &lt;- 
  },
  
  compute = function() {
    # return proportion of correct predictions
  }
)</code></pre>
<script type="application/json" data-opts-chunk="1">{"fig.width":6.5,"fig.height":4,"fig.retina":2,"fig.align":"default","fig.keep":"high","fig.show":"asis","out.width":624,"warning":true,"error":false,"message":true,"exercise.df_print":"paged","exercise.checker":"NULL"}</script>
</div>
<div class="tutorial-exercise-support" data-label="custom-metric-hint" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>my_accuracy &lt;- luz_metric(
  abbrev = &quot;my_acc&quot;, 
  
  initialize = function() {
    self$correct &lt;- 0
    self$total &lt;- 0
  },
 
  update = function(preds, target) {
    pred &lt;- torch::torch_argmax(preds, dim = 2)
    self$correct &lt;- self$correct + 
      (pred == target)$
      to(dtype = torch::torch_float())$
      sum()$
      item()
    self$total &lt;- self$total + pred$numel()
  },
  
  compute = function() {
    self$correct/self$total
  }
)</code></pre>
</div>
</div>
</div>
<div id="section-time-series-forecasting" class="section level2">
<h2>Time-series forecasting</h2>
<p>To illustrate time-series forecasting with <code>torch</code>, we make use of the <code>vic_elec</code> dataset, available through package <code>tsibbledata</code>. It provides three years of half-hourly electricity demand for Victoria, Australia, augmented by same-resolution temperature information and a daily holiday indicator.</p>
<p>For faster training, we aggregate the data by day. We throw away everything but <code>Demand</code> itself, relying on the univariate series exclusively.</p>
<pre class="r"><code>vic_elec_daily &lt;- vic_elec %&gt;%
  select(Time, Demand) %&gt;%
  index_by(Date = date(Time)) %&gt;%
  summarise(
    Demand = sum(Demand) / 1e3) </code></pre>
<p>To quickly get an impression what we’re dealing with, it’s convenient to use <code>feasts::STL()</code>.</p>
<pre class="r"><code>cmp &lt;- vic_elec_daily %&gt;% 
  model(STL(Demand)) %&gt;% 
  components()

cmp %&gt;% autoplot()</code></pre>
<p>Before we create a <code>dataset</code>, a <code>dataloader</code>, and a model, let’s quickly talk about time-series prediction with deep learning in general.</p>
<div id="section-time-series-forecasting-with-deep-learning-in-a-nutshell" class="section level3">
<h3>Time-series forecasting with deep learning in a nutshell</h3>
<p>In a linear model, individual observations are independent. Their order does not matter. The same holds for sets of images (not the pixels <em>in</em> an image, though).</p>
<p>But with sequences, such as spoken language or consecutive-in-time measurements, the order is essential. We thus need neural network models that respect sequentiality.</p>
<p>Traditionally, the type of data we’re talking about has been the domain of <em>recurrent neural networks</em> (RNNs). They are called <em>recurrent</em> because, in addition to handling a new batch item at every (training) time step, they keep – and continuously update – an internal state. This is often referred to as the <em>hidden</em> <em>state</em>.</p>
<p>In this family of RNNs, the most-established model architectures are <em>Gated Recurrent Unit</em> (GRU) and <em>Long Short-Term Memory</em> (LSTM). LSTM differs from GRU in that it keeps an additional internal state, sometimes called <em>cell state</em>, that is said to enable it to keep longer-term remembrances. In this tutorial, we use GRUs only, but adapting the code for LSTM is a manageable effort.</p>
<p>For RNNs to learn temporal dependencies, the data need to be prepared in a way that each batch item contains information about several time steps. Let’s see how that works.</p>
</div>
<div id="section-creating-a-dataset-for-time-series-forecasting" class="section level3">
<h3>Creating a <code>dataset</code> for time-series forecasting</h3>
<p>In our introduction to <code>luz</code>, we were able to make use of a pre-existing <code>dataset</code> object, namely, <code>mnist_dataset()</code> provided by <code>torchvision</code>. Now, we will build a custom <code>dataset</code>.</p>
<div id="section-the-dataset-object" class="section level4">
<h4>The <code>dataset</code> object</h4>
<p><code>dataset</code>s are R6 objects that implement three methods: <code>initialize()</code>, <code>.getitem()</code>, and <code>.length()</code>. Here</p>
<ul>
<li><p><code>initialize()</code> is where the data are stored into instance variables (and possibly, pre-processed);</p></li>
<li><p><code>.length()</code> tells the caller (a <code>dataloader</code>, in general) how many items there are in the <code>dataset</code>; and</p></li>
<li><p><code>.getitem()</code> defines what exactly should be returned as a single <code>&lt;source, target&gt;</code> (i.e., (<code>x,y)</code> ) pair.</p></li>
</ul>
<p>The last one of these is where the “business logic” surfaces.</p>
</div>
<div id="section-a-time-series-dataset-for-one-step-ahead-prediction" class="section level4">
<h4>A time-series <code>dataset</code> for one-step-ahead prediction</h4>
<p>For each batch item to contain information about a sequence, <code>x</code> needs to be a vector of consecutive measurements. How many measurements? This depends on what we know about the time series (as well as experimentation).</p>
<p>As to <code>y</code>, it depends on the number of time steps we want to forecast ahead. Here, we start with a single step. (We’ll adapt this for multi-step prediction later.)</p>
<p>To allow for experimentation with the number of time steps to learn from, we make <code>elec_dataset()</code> configurable in that respect (see the <code>n_timesteps</code> parameter passed to <code>initialize()</code>).</p>
<p>Then, <em>for each item</em>, the <code>dataset</code> returns a list of <code>(x,y)</code>, where <code>x</code> is a vector of consecutive observations (starting at the current index), and <code>y</code> is the measurement right thereafter:</p>
<pre class="r"><code>elec_dataset &lt;- dataset(
  name = &quot;elec_dataset&quot;,
  
  initialize = function(x, n_timesteps) {
    
    self$n_timesteps &lt;- n_timesteps
    self$x &lt;- torch_tensor((x - train_mean) / train_sd)

  },
  
  .getitem = function(i) {
    
    start &lt;- i
    end &lt;- start + self$n_timesteps - 1
    
    list(
      x = self$x[start:end],
      y = self$x[end + 1]
    )
    
  },
  
  .length = function() {
    length(self$x) - self$n_timesteps
  }
)</code></pre>
<p>Now, we create instances of such a <code>dataset</code> for training as well as validation. We first need to extract the <code>Demand</code> feature from the <code>tsibble</code>:</p>
<pre class="r"><code>elec_train &lt;- vic_elec_daily %&gt;% 
  filter(year(Date) %in% c(2012, 2013)) %&gt;%
  as_tibble() %&gt;%
  select(Demand) %&gt;%
  as.matrix()

elec_valid &lt;- vic_elec_daily %&gt;% 
  filter(year(Date) == 2014) %&gt;%
  as_tibble() %&gt;%
  select(Demand) %&gt;%
  as.matrix()</code></pre>
<p>For better training performance, we standardize the data. To that end, we compute mean and standard deviation for the training set:</p>
<pre class="r"><code>train_mean &lt;- mean(elec_train)
train_sd &lt;- sd(elec_train)</code></pre>
<p>From inspection, two weeks seems like a reasonable time period to learn from:</p>
<pre class="r"><code>n_timesteps &lt;- 7 * 2

train_ds &lt;- elec_dataset(elec_train, n_timesteps)
valid_ds &lt;- elec_dataset(elec_valid, n_timesteps)

length(train_ds)</code></pre>
<p>Let’s verify the <code>dataset</code> returns what we expect it to.</p>
<p><code>x</code>, at some arbitrary index, should be a matrix, with fourteen rows and a single column, where the column corresponds to the single feature, and the rows hold the consecutive measurements. <code>y</code>, on the other hand, should be a vector of length one.</p>
<pre class="r"><code>train_ds[1]</code></pre>
</div>
<div id="section-creating-the-respective-dataloaders" class="section level4">
<h4>Creating the respective <code>dataloader</code>s</h4>
<pre class="r"><code>batch_size &lt;- 32

train_dl &lt;- train_ds %&gt;% dataloader(batch_size = batch_size, shuffle = TRUE)

valid_dl &lt;- valid_ds %&gt;% dataloader(batch_size = batch_size)</code></pre>
<p>While there is nothing new about the calls to <code>dataloader()</code> here, it is interesting to check the shape of the batches it returns.</p>
<pre class="r"><code>b &lt;- dataloader_make_iter(train_dl) %&gt;% dataloader_next()
b</code></pre>
<p>A batch of <code>x</code>s now has shape <code>(32, 14, 1)</code>. Since after batching, the batch items are found in the leftmost dimension, the consecutive time steps are now located in the second-from-the-left one.</p>
<p>This will turn out to be important because of the shape of the inputs expected by RNNs.</p>
</div>
</div>
<div id="section-model-1" class="section level3">
<h3>Model</h3>
<p>The model is basically just a wrapper for an RNN, with an add-on linear layer that outputs a single prediction.</p>
<div id="section-more-about-grus" class="section level4">
<h4>More about GRUs</h4>
<p>Before we look at the way the model makes use of the RNN (a GRU), let’s inspect how a GRU behaves individually. We will want to know</p>
<ul>
<li><p>what arguments it expects on instantiation;</p></li>
<li><p>what arguments it expects when called; and</p></li>
<li><p>what it returns.</p></li>
</ul>
<p>Firstly, to create a GRU, we need to at least pass it the number of input features and the number of units in the hidden layer. If our data has batch items in its first dimension, we also need to pass <code>batch_first = TRUE</code>. For example:</p>
<pre class="r"><code>gru &lt;- nn_gru(
  input_size = 1, # number of input features
  hidden_size = 5, # number of hidden (and output!) features
  batch_first = TRUE 
)</code></pre>
<p>Secondly, the expected input format (provided we’ve created the module “batch first”, like we did above) is: <code>(batch_size, num_timesteps, num_features)</code>.</p>
<p>Here’s some random data fitting the requirements:</p>
<pre class="r"><code># batch of 4, with 8 time steps each and a single feature
input &lt;- torch_randn(c(4, 8, 1))</code></pre>
<p>Finally, the GRU module returns a list of two things:</p>
<ul>
<li><p>the output, of shape <code>(batch_size, num_timesteps, num_hidden)</code> . (Again, presupposing “batch-first”.)</p></li>
<li><p>the final hidden state for the last time-step only, of shape <code>(1, batch_size, num_hidden)</code>.</p></li>
</ul>
<p>For a GRU (as opposed to LSTM), there is <em>no difference between hidden and output when it comes to the final time-step</em>.Thus, the second tensor in the above list provides no additional information.</p>
<pre class="r"><code>gru(input)</code></pre>
</div>
<div id="section-complete-prediction-module" class="section level4">
<h4>Complete prediction module</h4>
<p>The model takes the output from the last time-step and passes it to the linear output layer, resulting in a single predicted value.</p>
<pre class="r"><code>model &lt;- nn_module(
  
  initialize = function(input_size, hidden_size) {

    self$rnn &lt;- nn_gru(
        input_size = input_size,
        hidden_size = hidden_size,
        batch_first = TRUE
      )
    
    self$output &lt;- nn_linear(hidden_size, 1)
    
  },
  
  forward = function(x) {
    
    # list of [output, hidden]
    # we are interested in the final timestep only, so we can directly use [[2]]
    # but we want to remove the un-needed singleton dimension on the left
    x &lt;- self$rnn(x)[[2]]$squeeze(1)

    x %&gt;% self$output() 
  }
  
)</code></pre>
</div>
</div>
<div id="section-training-1" class="section level3">
<h3>Training</h3>
<pre class="r"><code>fitted &lt;- model %&gt;%
  setup(
    loss = nn_mse_loss(),
    optimizer = optim_adam,
    metrics = list(
     luz_metric_mse()
    )
  ) %&gt;%
  set_hparams(input_size = 1, hidden_size = 64) %&gt;%
  fit(train_dl, epochs = 20, valid_data = valid_dl, verbose = TRUE)</code></pre>
</div>
<div id="section-test-time-predictions" class="section level3">
<h3>Test-time predictions</h3>
<p>For testing and plotting, let’s use the first four months of the validation set. (Shortening the time window will make for a more useful plot.)</p>
<pre class="r"><code>vic_elec_test &lt;- vic_elec_daily %&gt;% 
  filter(year(Date) %in% c(2014), month(Date) %in% 1:4) 

elec_test &lt;- vic_elec_test %&gt;%
  as_tibble() %&gt;%
  select(Demand) %&gt;%
  as.matrix()

test_ds &lt;- elec_dataset(elec_test, n_timesteps)

test_dl &lt;- test_ds %&gt;% dataloader(batch_size = batch_size)</code></pre>
<p>Using <code>luz</code> to obtain the predictions:</p>
<pre class="r"><code>preds &lt;- predict(fitted, test_dl)
preds &lt;- as.numeric(preds)</code></pre>
<p>We can plot them against the ground truth:</p>
<pre class="r"><code>preds &lt;- c(rep(NA, n_timesteps), preds)

preds_ts &lt;- vic_elec_daily %&gt;% 
  filter(year(Date) %in% c(2014), month(Date) %in% 1:4) %&gt;%
  add_column(forecast = preds * train_sd + train_mean) %&gt;%
  pivot_longer(-Date) %&gt;%
  update_tsibble(key = name)

preds_ts %&gt;%
  autoplot() +
  scale_colour_manual(values = c(&quot;#08c5d1&quot;, &quot;#00353f&quot;)) +
  theme_minimal()</code></pre>
</div>
<div id="section-exercise-extending-the-model-to-multi-step-prediction" class="section level3">
<h3>Exercise: Extending the model to multi-step prediction</h3>
<p>Often, we want to forecast further into the future than just a single time-step. In an extended exercise, you’ll adapt <code>dataset</code> and model to enable multi-step-ahead prediction.</p>
<div id="section-required-changes" class="section level4">
<h4>Required changes</h4>
<div id="section-dataset" class="section level5">
<h5><code>dataset</code></h5>
<p>In the <code>dataset</code>, we now distinguish between the number of time-steps to base learning on (<code>n_timesteps</code>), and the number of time-steps to forecast (<code>n_forecast</code>).</p>
<p>In <code>.getitem()</code>, the tensor returned in <code>x</code> remains unchanged, while in <code>y</code>, we return <code>n_forecast</code> values immediately following the last <code>x</code> component.</p>
<p>Due to the new logic, <code>.length()</code> will have to change as well.</p>
</div>
<div id="section-model-2" class="section level5">
<h5>Model</h5>
<p>The model now should output <code>n_forecast</code> values. The simplest way to achieve this is to have the final linear layer return <code>n_forecast</code> values instead of a single one. However, depending on the data this may or may not result in satisfying performance.</p>
<p>Instead, we can chain several linear layers, joined by nonlinearities. Put differently, we’ll have a “network inside the network” – the GRU will be followed by a feedforward neural network, also referred to as Multi-Layer Perceptron (MLP).</p>
<p>In this second and significantly more powerful approach, it is easy to overfit to the training set. To counteract overfitting, we additionally put in a <code>dropout</code> layer. With <em>dropout</em>, a configurable amount of randomness is added to the training process (but neither to validation nor to testing). Technically, this is achieved by randomly zeroing out the desired fraction of elements in the layer’s input tensor.</p>
<p>Below, you’ll find instructions to implement the second alternative.</p>
</div>
</div>
<div id="section-exercise-part-1-adapting-the-dataset" class="section level4">
<h4>Exercise part 1: Adapting the <code>dataset</code></h4>
<p>Please start by making the above-mentioned changes in the <code>dataset</code>.</p>
<div class="tutorial-exercise" data-label="multi-step-ds" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>elec_dataset &lt;- dataset(
  name = &quot;elec_dataset&quot;,
  
  initialize = function(x, n_timesteps, n_forecast) {
    
  },
  
  .getitem = function(i) {
    
  
  },
  
  .length = function() {
    
  }
)</code></pre>
<script type="application/json" data-opts-chunk="1">{"fig.width":6.5,"fig.height":4,"fig.retina":2,"fig.align":"default","fig.keep":"high","fig.show":"asis","out.width":624,"warning":true,"error":false,"message":true,"exercise.df_print":"paged","exercise.checker":"NULL"}</script>
</div>
<div class="tutorial-exercise-support" data-label="multi-step-ds-hint" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>elec_dataset &lt;- dataset(
  name = &quot;elec_dataset&quot;,
  
  initialize = function(x, n_timesteps, n_forecast) {
    
    self$n_timesteps &lt;- n_timesteps
    self$n_forecast &lt;- n_forecast
    self$x &lt;- torch_tensor((x - train_mean) / train_sd)

  },
  
  .getitem = function(i) {
    
    start &lt;- i
    end &lt;- start + self$n_timesteps - 1
    pred_length &lt;- self$n_forecast
    
    list(
      x = self$x[start:end],
      y = self$x[(end + 1):(end + pred_length)]$squeeze(2)
    )
    
  },
  
  .length = function() {
    length(self$x) - self$n_timesteps - self$n_forecast + 1
  }
)</code></pre>
</div>
<p>Once you’ve updated the <code>dataset</code> definition, you’ll need to recreate <code>train_ds</code> and <code>valid_ds</code>. Pick a number for the forecast window (<code>n_forecast</code>), for example, fourteen days:</p>
<pre class="r"><code>n_timesteps &lt;- 7 * 2
n_forecast &lt;- 7 * 2 

train_ds &lt;- elec_dataset(elec_train, n_timesteps, n_forecast)

valid_ds &lt;- elec_dataset(elec_valid, n_timesteps, n_forecast)</code></pre>
<p>To check your implementation, make sure that</p>
<pre class="r"><code>length(train_ds)
train_ds[1]</code></pre>
<p>work correctly.</p>
<p>To proceed to the next step, you’ll also need to recreate the <code>dataloader</code>s.</p>
<pre class="r"><code>batch_size &lt;- 32
train_dl &lt;- train_ds %&gt;% dataloader(batch_size = batch_size, shuffle = TRUE)

valid_dl &lt;- valid_ds %&gt;% dataloader(batch_size = batch_size)</code></pre>
</div>
<div id="section-exercise-part-2-adapting-the-model" class="section level4">
<h4>Exercise part 2: Adapting the model</h4>
<p>Now, adapt the model, in the sense described above.</p>
<div class="tutorial-exercise" data-label="multi-step-model" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>model &lt;- nn_module(
  
  # to avoid hard coding specific values, you can add more &quot;hparams&quot; here
  initialize = function(input_size, hidden_size, ...) {
    
    self$rnn &lt;- nn_gru(
        input_size = input_size,
        hidden_size = hidden_size,
        batch_first = TRUE
      )
    
    # a feedforward neural network, using nn_dropout before the output layer
    self$mlp &lt;- nn_sequential(
      
      
      
    )
    
  },
  
  forward = function(x) {
    
    
    
  }
  
)</code></pre>
<script type="application/json" data-opts-chunk="1">{"fig.width":6.5,"fig.height":4,"fig.retina":2,"fig.align":"default","fig.keep":"high","fig.show":"asis","out.width":624,"warning":true,"error":false,"message":true,"exercise.df_print":"paged","exercise.checker":"NULL"}</script>
</div>
<div class="tutorial-exercise-support" data-label="multi-step-model-hint" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>model &lt;- nn_module(
  
  initialize = function(input_size, hidden_size, linear_size, output_size, dropout = 0) {
    
    self$rnn &lt;- nn_gru(
        input_size = input_size,
        hidden_size = hidden_size,
        batch_first = TRUE
      )
    
    self$mlp &lt;- nn_sequential(
      nn_linear(hidden_size, linear_size),
      nn_relu(),
      nn_dropout(dropout),
      nn_linear(linear_size, output_size)
    )
    
  },
  
  forward = function(x) {
    
    x &lt;- self$rnn(x)
    # pass last timestep of RNN output to MLP
    x[[1]][ ,-1, ..] %&gt;% 
      self$mlp()
    
  }
  
)</code></pre>
</div>
</div>
<div id="section-exercise-part-3-run-training" class="section level4">
<h4>Exercise part 3: Run training</h4>
<p>Training looks much like above, apart from the fact that you’ll need to set more <code>hparams</code>.</p>
<div class="tutorial-exercise" data-label="multi-step-fit" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>#fitted &lt;-</code></pre>
<script type="application/json" data-opts-chunk="1">{"fig.width":6.5,"fig.height":4,"fig.retina":2,"fig.align":"default","fig.keep":"high","fig.show":"asis","out.width":624,"warning":true,"error":false,"message":true,"exercise.df_print":"paged","exercise.checker":"NULL"}</script>
</div>
<div class="tutorial-exercise-support" data-label="multi-step-fit-hint" data-caption="Code" data-completion="1" data-diagnostics="1" data-startover="1" data-lines="0">
<pre class="text"><code>fitted &lt;- model %&gt;%
  setup(
    loss = nn_mse_loss(),
    optimizer = optim_adam,
    metrics = list(
     luz_metric_mse()
    )
  ) %&gt;%
  set_hparams(input_size = 1, hidden_size = 64, linear_size = 128,
             output_size = n_forecast, dropout = 0.5) %&gt;%
  fit(train_dl, epochs = 20, valid_data = valid_dl, verbose = TRUE)</code></pre>
</div>
<p>Once you’re done, here is some code to visualize a selection of forecast sequences (feel free to adapt).</p>
<pre class="r"><code>preds &lt;- predict(fitted, test_dl)
preds &lt;- as.matrix(preds)</code></pre>
<pre class="r"><code>test_pred1 &lt;- preds[1, ]
test_pred1 &lt;- c(rep(NA, n_timesteps), test_pred1, rep(NA, nrow(vic_elec_test) - n_timesteps - n_forecast))

test_pred2 &lt;- preds[21, ]
test_pred2 &lt;- c(rep(NA, n_timesteps + 20), test_pred2, rep(NA, nrow(vic_elec_test) - 20 - n_timesteps - n_forecast))

test_pred3 &lt;- preds[41, ]
test_pred3 &lt;- c(rep(NA, n_timesteps + 40), test_pred3, rep(NA, nrow(vic_elec_test) - 40 - n_timesteps - n_forecast))

test_pred4 &lt;- preds[61, ]
test_pred4 &lt;- c(rep(NA, n_timesteps + 60), test_pred4, rep(NA, nrow(vic_elec_test) - 60 - n_timesteps - n_forecast))

test_pred5 &lt;- preds[81, ]
test_pred5 &lt;- c(rep(NA, n_timesteps + 80), test_pred5, rep(NA, nrow(vic_elec_test) - 80 - n_timesteps - n_forecast))

preds_ts &lt;- vic_elec_test %&gt;% 
  add_column(
    ex_1 = test_pred1 * train_sd + train_mean,
    ex_2 = test_pred2 * train_sd + train_mean,
    ex_3 = test_pred3 * train_sd + train_mean,
    ex_4 = test_pred4 * train_sd + train_mean,
    ex_5 = test_pred5 * train_sd + train_mean) %&gt;%
  pivot_longer(-Date) %&gt;%
  update_tsibble(key = name)


preds_ts %&gt;%
  autoplot() +
  scale_color_hue(h = c(80, 300), l = 70) +
  theme_minimal()</code></pre>
</div>
</div>
</div>
<div id="section-qa" class="section level2">
<h2>Q&amp;A</h2>
<p>Questions?</p>
<p>Stay in contact:</p>
<ul>
<li><p>GitHub: <a href="https://github.com/torch">torch</a>, <a href="https://github.com/luz">luz</a>, …</p></li>
<li><p>Discord: <a href="https://discord.com/invite/s3D5cKhBkx">torch for R</a></p></li>
<li><p>Blog: <a href="https://blogs.rstudio.com/ai/">RStudio AI Blog</a></p></li>
</ul>
Thanks for your attention!! 
<script type="application/shiny-prerendered" data-context="server-start">
library(learnr)
library(torch)
library(luz)
library(torchvision)
library(tidyverse)
library(tsibble)
library(tsibbledata)
library(lubridate)
library(fable)
library(feasts)
library(zeallot)

knitr::opts_chunk$set(echo = FALSE)
</script>
 
<script type="application/shiny-prerendered" data-context="server">
learnr:::register_http_handlers(session, metadata = NULL)
</script>
 
<script type="application/shiny-prerendered" data-context="server">
session$onSessionEnded(function() {
        learnr:::session_stop_event(session)
      })
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-tensors1-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-tensors1-code-editor`)), session)
output$`tutorial-exercise-tensors1-output` <- renderUI({
  `tutorial-exercise-tensors1-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-tensors2-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-tensors2-code-editor`)), session)
output$`tutorial-exercise-tensors2-output` <- renderUI({
  `tutorial-exercise-tensors2-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-tensors3-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-tensors3-code-editor`)), session)
output$`tutorial-exercise-tensors3-output` <- renderUI({
  `tutorial-exercise-tensors3-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-tensors4-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-tensors4-code-editor`)), session)
output$`tutorial-exercise-tensors4-output` <- renderUI({
  `tutorial-exercise-tensors4-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-tensors5-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-tensors5-code-editor`)), session)
output$`tutorial-exercise-tensors5-output` <- renderUI({
  `tutorial-exercise-tensors5-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-autograd-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-autograd-code-editor`)), session)
output$`tutorial-exercise-autograd-output` <- renderUI({
  `tutorial-exercise-autograd-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-modules-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-modules-code-editor`)), session)
output$`tutorial-exercise-modules-output` <- renderUI({
  `tutorial-exercise-modules-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-custom-callback-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-custom-callback-code-editor`)), session)
output$`tutorial-exercise-custom-callback-output` <- renderUI({
  `tutorial-exercise-custom-callback-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-custom-metric-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-custom-metric-code-editor`)), session)
output$`tutorial-exercise-custom-metric-output` <- renderUI({
  `tutorial-exercise-custom-metric-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-multi-step-ds-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-multi-step-ds-code-editor`)), session)
output$`tutorial-exercise-multi-step-ds-output` <- renderUI({
  `tutorial-exercise-multi-step-ds-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-multi-step-model-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-multi-step-model-code-editor`)), session)
output$`tutorial-exercise-multi-step-model-output` <- renderUI({
  `tutorial-exercise-multi-step-model-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-multi-step-fit-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-multi-step-fit-code-editor`)), session)
output$`tutorial-exercise-multi-step-fit-output` <- renderUI({
  `tutorial-exercise-multi-step-fit-result`()
})
</script>
 <!--html_preserve-->
<script type="application/shiny-prerendered" data-context="dependencies">
{"type":"list","attributes":{},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["header-attrs"]},{"type":"character","attributes":{},"value":["2.8"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/pandoc"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["header-attrs.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.8"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["jquery"]},{"type":"character","attributes":{},"value":["1.11.3"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/jquery"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquery.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.8"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["bootstrap"]},{"type":"character","attributes":{},"value":["3.3.5"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/bootstrap"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["viewport"]}},"value":[{"type":"character","attributes":{},"value":["width=device-width, initial-scale=1"]}]},{"type":"character","attributes":{},"value":["js/bootstrap.min.js","shim/html5shiv.min.js","shim/respond.min.js"]},{"type":"character","attributes":{},"value":["css/cerulean.min.css"]},{"type":"character","attributes":{},"value":["<style>h1 {font-size: 34px;}\n       h1.title {font-size: 38px;}\n       h2 {font-size: 30px;}\n       h3 {font-size: 24px;}\n       h4 {font-size: 18px;}\n       h5 {font-size: 16px;}\n       h6 {font-size: 12px;}\n       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}\n       pre:not([class]) { background-color: white }<\/style>"]},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.8"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["pagedtable"]},{"type":"character","attributes":{},"value":["1.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/pagedtable-1.1"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["js/pagedtable.js"]},{"type":"character","attributes":{},"value":["css/pagedtable.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.8"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["highlightjs"]},{"type":"character","attributes":{},"value":["9.12.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/highlightjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["highlight.js"]},{"type":"character","attributes":{},"value":["textmate.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.8"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial"]},{"type":"character","attributes":{},"value":["0.10.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial.js"]},{"type":"character","attributes":{},"value":["tutorial.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial-autocompletion"]},{"type":"character","attributes":{},"value":["0.10.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial-autocompletion.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial-diagnostics"]},{"type":"character","attributes":{},"value":["0.10.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial-diagnostics.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial-format"]},{"type":"character","attributes":{},"value":["0.10.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmarkdown/templates/tutorial/resources"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial-format.js"]},{"type":"character","attributes":{},"value":["tutorial-format.css","rstudio-theme.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["jquery"]},{"type":"character","attributes":{},"value":["1.11.3"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/jquery"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquery.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.8"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["navigation"]},{"type":"character","attributes":{},"value":["1.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/navigation-1.1"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tabsets.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.8"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["highlightjs"]},{"type":"character","attributes":{},"value":["9.12.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/highlightjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["highlight.js"]},{"type":"character","attributes":{},"value":["default.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.8"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["jquery"]},{"type":"character","attributes":{},"value":["1.11.3"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/jquery"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquery.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.8"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["font-awesome"]},{"type":"character","attributes":{},"value":["5.1.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/fontawesome"]}]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["css/all.css","css/v4-shims.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.8"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["bootbox"]},{"type":"character","attributes":{},"value":["4.4.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/bootbox"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["bootbox.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["idb-keyvalue"]},{"type":"character","attributes":{},"value":["3.2.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/idb-keyval"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["idb-keyval-iife-compat.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[false]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial"]},{"type":"character","attributes":{},"value":["0.10.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial.js"]},{"type":"character","attributes":{},"value":["tutorial.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial-autocompletion"]},{"type":"character","attributes":{},"value":["0.10.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial-autocompletion.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial-diagnostics"]},{"type":"character","attributes":{},"value":["0.10.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial-diagnostics.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]}]}
</script>
<!--/html_preserve-->
<!--html_preserve-->
<script type="application/shiny-prerendered" data-context="execution_dependencies">
{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["packages"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["packages","version"]},"class":{"type":"character","attributes":{},"value":["data.frame"]},"row.names":{"type":"integer","attributes":{},"value":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98]}},"value":[{"type":"character","attributes":{},"value":["anytime","assertthat","backports","base","bit","bit64","broom","bslib","callr","cellranger","cli","colorspace","compiler","coro","crayon","datasets","DBI","dbplyr","digest","distributional","dplyr","ellipsis","evaluate","fable","fabletools","fansi","farver","fastmap","feasts","forcats","fs","generics","ggplot2","glue","graphics","grDevices","grid","gtable","haven","hms","htmltools","htmlwidgets","httpuv","httr","jquerylib","jsonlite","knitr","later","learnr","lifecycle","lubridate","luz","magrittr","markdown","methods","mime","modelr","munsell","pillar","pkgconfig","processx","promises","ps","purrr","R6","Rcpp","readr","readxl","reprex","rlang","rmarkdown","rprojroot","rstudioapi","rvest","sass","scales","shiny","stats","stringi","stringr","tibble","tidyr","tidyselect","tidyverse","tools","torch","torchvision","tsibble","tsibbledata","utf8","utils","vctrs","withr","xfun","xml2","xtable","yaml","zeallot"]},{"type":"character","attributes":{},"value":["0.3.9","0.2.1","1.2.1","4.0.5","4.0.4","4.0.5","0.7.6","0.2.5.1","3.7.0","1.1.0","2.5.0","2.0-1","4.0.5","1.0.1","1.4.1","4.0.5","1.1.1","2.1.1","0.6.27","0.2.2","1.0.6","0.3.2","0.14","0.3.1","0.3.1","0.5.0","2.1.0","1.1.0","0.2.1","0.5.1","1.5.0","0.1.0","3.3.3","1.4.2","4.0.5","4.0.5","4.0.5","0.3.0","2.4.1","1.1.0","0.5.1.1","1.5.3","1.6.1","1.4.2","0.1.4","1.7.2","1.33","1.2.0","0.10.1","1.0.0","1.7.10","0.0.0.9000","2.0.1","1.1","4.0.5","0.10","0.1.8","0.5.0","1.6.1","2.0.3","3.5.2","1.2.0.1","1.6.0","0.3.4","2.5.0","1.0.6","1.4.0","1.3.1","2.0.0","0.4.11","2.8","2.0.2","0.13","1.0.0","0.4.0","1.1.1","1.6.0","4.0.5","1.6.2","1.4.0","3.1.2","1.1.3","1.1.1","1.3.1","4.0.5","0.3.0.9004","0.3.0.9000","1.0.1","0.3.0","1.2.1","4.0.5","0.3.8","2.4.2","0.23","1.3.2","1.8-4","2.2.1","0.1.0"]}]}]}
</script>
<!--/html_preserve-->
</div>

</div> <!-- topics -->

<div class="topicsContainer">
<div class="topicsPositioner">
<div class="band">
<div class="bandContent topicsListContainer">

<!-- begin doc-metadata -->
<div id="doc-metadata">
<h2 class="title toc-ignore" style="display:none;">Getting started with torch</h2>
</div>
<!-- end doc-metadata -->

</div> <!-- bandContent.topicsListContainer -->
</div> <!-- band -->
</div> <!-- topicsPositioner -->
</div> <!-- topicsContainer -->


</div> <!-- bandContent page -->
</div> <!-- pageContent band -->




<script>
// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});
</script>


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>


</body>

</html>
